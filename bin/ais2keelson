#!/usr/bin/env python3

"""
Command line utility tool for processing input from stdin. Each line on the
input stream is base64 encoded with no wrapping and ended with a newline.
"""
import sys
import math
import time
import json
import logging
import argparse
import threading
from typing import Union
from functools import partial

import zenoh
from geopy.distance import distance
from pyais.queue import NMEAQueue
from pyais.filter import GridFilter
from pyais.messages import (
    MessageType1,
    MessageType2,
    MessageType3,
    MessageType5,
    MessageType18,
)

from keelson import enclose, construct_pubsub_key, construct_rpc_key
from keelson.payloads.Primitives_pb2 import (
    TimestampedBytes,
    TimestampedFloat,
    TimestampedString,
)
from keelson.payloads.LocationFix_pb2 import LocationFix

logger = logging.getLogger("ais2keelson")


PUBLISHERS: dict[str, zenoh.Publisher] = {}
QUEUE = NMEAQueue()

# Filters with initial settings
GRID_FILTER = GridFilter(
    lat_max=math.inf, lat_min=-math.inf, lon_max=math.inf, lon_min=-math.inf
)

MSG5_DB: dict[int, MessageType5] = {}

# Config callbacks


def _get_config(key_expr: zenoh.KeyExpr, query: zenoh.Query):
    logger.debug("Received query on: %s", query.key_expr)
    logger.debug("Returning current config on key: %s", key_expr)

    payload = json.dumps(
        {
            "lat_max": GRID_FILTER.lat_max,
            "lat_min": GRID_FILTER.lat_min,
            "lon_max": GRID_FILTER.lon_max,
            "lon_min": GRID_FILTER.lon_min,
        }
    )
    query.reply(key_expr, payload.encode())


def _set_config(session: zenoh.Session, key_expr: zenoh.KeyExpr, query: zenoh.Query):
    try:
        logger.debug("Received query on: %s", query.key_expr)
        parameters = json.loads(query.payload.to_bytes())

        for key, value in parameters.items():
            setattr(GRID_FILTER, key, value)

        query.reply(key_expr, "Success!")

    except Exception as exc:
        logger.exception("Failed to respond to query...")
        query.reply_err(str(exc))

    finally:
        # Publish updated config to ensure we log it
        payload = json.dumps(
            {
                "lat_max": GRID_FILTER.lat_max,
                "lat_min": GRID_FILTER.lat_min,
                "lon_max": GRID_FILTER.lon_max,
                "lon_min": GRID_FILTER.lon_min,
            }
        )
        session.put(key_expr, payload)


# Helper functions that should be moved to keelson-sdk?


def enclose_from_bytes(value: bytes) -> bytes:
    payload = TimestampedBytes()
    payload.timestamp.FromNanoseconds(time.time_ns())
    payload.value = value

    return enclose(payload.SerializeToString())


def enclose_from_float(value: float) -> bytes:
    payload = TimestampedFloat()
    payload.timestamp.FromNanoseconds(time.time_ns())
    payload.value = value

    return enclose(payload.SerializeToString())


def enclose_from_string(value: str) -> bytes:
    payload = TimestampedString()
    payload.timestamp.FromNanoseconds(time.time_ns())
    payload.value = value

    return enclose(payload.SerializeToString())


def enclose_from_lon_lat(longitude: float, latitude: float) -> bytes:
    payload = LocationFix()
    payload.timestamp.FromNanoseconds(time.time_ns())
    payload.latitude = latitude
    payload.longitude = longitude

    return enclose(payload.SerializeToString())


# Helper function for translating the antenna position


def _translate_position_to_geometrical_center(
    msg123: Union[MessageType1, MessageType2, MessageType3]
):
    if not (msg5 := MSG5_DB.get(msg123.mmsi)):
        # We have no msg5 yet, not much we can do here...
        return

    # How much should we move it?
    move_to_bow = (msg5.to_bow - msg5.to_stern) / 2
    move_to_starboard = (msg5.to_starboard - msg5.to_port) / 2

    # Make the move
    p1 = distance(meters=move_to_bow).destination(
        (msg123.lat, msg123.lon), msg123.heading
    )
    p2 = distance(meters=move_to_starboard).destination(p1, msg123.heading + 90)

    # Update msg123 with corrected values
    msg123.lat = p2.latitude
    msg123.lon = p2.longitude


# AIS Message Handlers


def _handle_AIS_message_123(msg: Union[MessageType1, MessageType2, MessageType3]):
    yield "location_fix", enclose_from_lon_lat(msg.lon, msg.lat)
    yield "rate_of_turn_degpm", enclose_from_float(msg.turn)
    yield "heading_deg", enclose_from_float(msg.heading)
    yield "course_over_ground_deg", enclose_from_float(msg.course)
    yield "speed_over_ground_knots", enclose_from_float(msg.speed)


def _handle_AIS_message_5(msg: MessageType5):
    yield "mean_draught_m", msg.draught
    yield "length_over_all_m", msg.to_bow + msg.to_stern
    yield "breadth_over_all_m", msg.to_port + msg.to_starboard


def _handle_AIS_message_18(msg: MessageType18):
    yield "location_fix", enclose_from_lon_lat(msg.lon, msg.lat)
    yield "heading_deg", enclose_from_float(msg.heading)
    yield "course_over_ground_deg", enclose_from_float(msg.course)
    yield "speed_over_ground_knots", enclose_from_float(msg.speed)


HANDLERS = {
    1: _handle_AIS_message_123,
    2: _handle_AIS_message_123,
    3: _handle_AIS_message_123,
    5: _handle_AIS_message_5,
    18: _handle_AIS_message_18,
}


# Main loop


def run(session: zenoh.Session, args: argparse.Namespace):
    # Optionally create a publisher for raw payloads

    def _dispatcher():
        logger.debug("Dispatcher thread started!")

        # Wrap the queue in a generator so that we can...
        def _message_generator():
            while True:
                try:
                    logger.debug("Waiting for new message from Queue...")
                    yield QUEUE.get().decode()
                except Exception:
                    logger.exception("Failed to decode AIS Sentence!")

        # ...use the built-in filtering functions of pyais
        for msg in GRID_FILTER.filter(_message_generator()):
            logger.debug("Got new msg: %s", msg)

            mmsi = msg.mmsi

            # Handle correction of antenna position
            if msg.msg_type == 5:
                MSG5_DB[mmsi] = msg
            elif msg.msg_type in (1, 2, 3):
                _translate_position_to_geometrical_center(msg)

            if args.publish_json:
                if not (pub := PUBLISHERS.get("json")):
                    key = construct_pubsub_key(
                        args.realm,
                        args.entity_id,
                        "raw_json",
                        f"{args.source_id}/{mmsi}",
                    )
                    pub = PUBLISHERS["json"] = session.declare_publisher(key)

                pub.put(enclose_from_bytes(msg.to_json().encode()))

                if args.publish_fields and (handler := HANDLERS.get(msg.msg_type)):
                    for subject, envelope in handler(msg):
                        # See if we have a publisher for this subject already, otherwise create it
                        if not (pub := PUBLISHERS.get(subject)):
                            key = construct_pubsub_key(
                                args.realm,
                                args.entity_id,
                                subject,
                                f"{args.source_id}/{mmsi}",
                            )
                            pub = PUBLISHERS[subject] = session.declare_publisher(key)

                        pub.put(envelope)

    # Start a background thread for dispatching NMEA messages
    t = threading.Thread(target=_dispatcher, daemon=True)
    t.start()

    # Continuously read from STDIN
    for line in sys.stdin.buffer:
        logger.debug("Read from stdin: %s", line)

        # Publish raw messages if required
        if args.publish_raw:
            logger.debug("Publishing raw")

            # See if we have a publisher already, otherwise create it
            if not (pub := PUBLISHERS.get("raw")):
                key = construct_pubsub_key(
                    args.realm, args.entity_id, "raw", args.source_id
                )

                logger.debug("Creating new publisher for key: %s", key)
                pub = PUBLISHERS["raw"] = session.declare_publisher(key)

            pub.put(enclose_from_bytes(line))

        # Put into NMEAQueue for further handling
        # The queue handles the assembly of fragmented messages
        if args.publish_json or args.publish_fields:
            logger.debug("Adding to NMEA queue")
            QUEUE.put_line(line)


# Entrypoint


def main():
    parser = argparse.ArgumentParser(
        prog="ais2keelson",
        formatter_class=argparse.ArgumentDefaultsHelpFormatter,
    )

    parser.add_argument("--log-level", type=int, default=logging.INFO)

    parser.add_argument(
        "--mode",
        "-m",
        dest="mode",
        choices=["peer", "client"],
        type=str,
        help="The zenoh session mode.",
    )

    parser.add_argument(
        "--connect",
        action="append",
        type=str,
        help="Endpoints to connect to, in case multicast is not working. ex. tcp/localhost:7447",
    )

    parser.add_argument("-r", "--realm", type=str, required=True)
    parser.add_argument("-e", "--entity-id", type=str, required=True)
    parser.add_argument("-s", "--source-id", type=str, required=True)

    parser.add_argument("--publish-raw", default=False, action="store_true")
    parser.add_argument("--publish-json", default=False, action="store_true")
    parser.add_argument("--publish-fields", default=False, action="store_true")

    # Parse arguments and start doing our thing
    args = parser.parse_args()

    # Setup logger
    logging.basicConfig(
        format="%(asctime)s %(levelname)s %(name)s %(message)s", level=args.log_level
    )
    logging.captureWarnings(True)

    # Put together zenoh session configuration
    conf = zenoh.Config()

    if args.mode is not None:
        conf.insert_json5("mode", json.dumps(args.mode))
    if args.connect is not None:
        conf.insert_json5("connect/endpoints", json.dumps(args.connect))

    # Construct session and run
    logger.info("Opening Zenoh session...")
    with zenoh.open(conf) as session:
        # Configure configuration queryables
        get_config_key = construct_rpc_key(
            args.realm, args.entity_id, "get_config", "na", "na", args.source_id
        )
        session.declare_queryable(
            get_config_key, partial(_get_config, get_config_key), complete=True
        )

        set_config_key = construct_rpc_key(
            args.realm, args.entity_id, "set_config", "na", "na", args.source_id
        )
        session.declare_queryable(
            set_config_key, partial(_set_config, session, set_config_key), complete=True
        )

        # Time to run!
        run(session, args)


if __name__ == "__main__":
    main()
